{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Amazon Fine Food Reviews Analysis\n",
    "\n",
    "\n",
    "Data Source: https://www.kaggle.com/snap/amazon-fine-food-reviews <br>\n",
    "\n",
    "EDA: https://nycdatascience.com/blog/student-works/amazon-fine-foods-visualization/\n",
    "\n",
    "\n",
    "The Amazon Fine Food Reviews dataset consists of reviews of fine foods from Amazon.<br>\n",
    "\n",
    "Number of reviews: 568,454<br>\n",
    "Number of users: 256,059<br>\n",
    "Number of products: 74,258<br>\n",
    "Timespan: Oct 1999 - Oct 2012<br>\n",
    "Number of Attributes/Columns in data: 10 \n",
    "\n",
    "Attribute Information:\n",
    "\n",
    "1. Id\n",
    "2. ProductId - unique identifier for the product\n",
    "3. UserId - unqiue identifier for the user\n",
    "4. ProfileName\n",
    "5. HelpfulnessNumerator - number of users who found the review helpful\n",
    "6. HelpfulnessDenominator - number of users who indicated whether they found the review helpful or not\n",
    "7. Score - rating between 1 and 5\n",
    "8. Time - timestamp for the review\n",
    "9. Summary - brief summary of the review\n",
    "10. Text - text of the review\n",
    "\n",
    "\n",
    "#### Objective:\n",
    "Given a review, determine whether the review is positive (rating of 4 or 5) or negative (rating of 1 or 2).\n",
    "\n",
    "<br>\n",
    "[Q] How to determine if a review is positive or negative?<br>\n",
    "<br> \n",
    "[Ans] We could use Score/Rating. A rating of 4 or 5 can be cosnidered as a positive review. A rating of 1 or 2 can be considered as negative one. A review of rating 3 is considered nuetral and such reviews are ignored from our analysis. This is an approximate and proxy way of determining the polarity (positivity/negativity) of a review.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [1]. Reading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [5] Assignment 7: SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<ol>\n",
    "    <li><strong>Apply SVM on these feature sets</strong>\n",
    "        <ul>\n",
    "            <li><font color='red'>SET 1:</font>Review text, preprocessed one converted into vectors using (BOW)</li>\n",
    "            <li><font color='red'>SET 2:</font>Review text, preprocessed one converted into vectors using (TFIDF)</li>\n",
    "            <li><font color='red'>SET 3:</font>Review text, preprocessed one converted into vectors using (AVG W2v)</li>\n",
    "            <li><font color='red'>SET 4:</font>Review text, preprocessed one converted into vectors using (TFIDF W2v)</li>\n",
    "        </ul>\n",
    "    </li>\n",
    "    <br>\n",
    "    <li><strong>Procedure</strong>\n",
    "        <ul>\n",
    "    <li>You need to work with 2 versions of SVM\n",
    "        <ul><li>Linear kernel</li>\n",
    "            <li>RBF kernel</li></ul>\n",
    "    <li>When you are working with linear kernel, use SGDClassifier’ with hinge loss because it is computationally less expensive.</li>\n",
    "    <li>When you are working with ‘SGDClassifier’ with hinge loss and trying to find the AUC\n",
    "        score, you would have to use <a href='https://scikit-learn.org/stable/modules/generated/sklearn.calibration.CalibratedClassifierCV.html'>CalibratedClassifierCV</a></li>\n",
    "    <li>Similarly, like kdtree of knn, when you are working with RBF kernel it's better to reduce\n",
    "the number of dimensions. You can put min_df = 10, max_features = 500 and consider a sample size of 40k points.</li>                \n",
    "        </ul>\n",
    "    </li>\n",
    "    <br>\n",
    "    <li><strong>Hyper paramter tuning (find best alpha in range [10^-4 to 10^4], and the best penalty among 'l1', 'l2')</strong>\n",
    "        <ul>\n",
    "    <li>Find the best hyper parameter which will give the maximum <a href='https://www.appliedaicourse.com/course/applied-ai-course-online/lessons/receiver-operating-characteristic-curve-roc-curve-and-auc-1/'>AUC</a> value</li>\n",
    "    <li>Find the best hyper paramter using k-fold cross validation or simple cross validation data</li>\n",
    "    <li>Use gridsearch cv or randomsearch cv or you can also write your own for loops to do this task of hyperparameter tuning</li>          \n",
    "        </ul>\n",
    "    </li>\n",
    "    <br>\n",
    "    <li><strong>Feature importance</strong>\n",
    "        <ul>\n",
    "    <li>When you are working on the linear kernel with BOW or TFIDF please print the top 10 best\n",
    "features for each of the positive and negative classes.</li>\n",
    "        </ul>\n",
    "    </li>\n",
    "    <br>\n",
    "    <li><strong>Feature engineering</strong>\n",
    "        <ul>\n",
    "    <li>To increase the performance of your model, you can also experiment with with feature engineering like :</li>\n",
    "            <ul>\n",
    "            <li>Taking length of reviews as another feature.</li>\n",
    "            <li>Considering some features from review summary as well.</li>\n",
    "        </ul>\n",
    "        </ul>\n",
    "    </li>\n",
    "    <br>\n",
    "    <li><strong>Representation of results</strong>\n",
    "        <ul>\n",
    "    <li>You need to plot the performance of model both on train data and cross validation data for each hyper parameter, like shown in the figure.\n",
    "    <img src='train_cv_auc.JPG' width=300px></li>\n",
    "    <li>Once after you found the best hyper parameter, you need to train your model with it, and find the AUC on test data and plot the ROC curve on both train and test.\n",
    "    <img src='train_test_auc.JPG' width=300px></li>\n",
    "    <li>Along with plotting ROC curve, you need to print the <a href='https://www.appliedaicourse.com/course/applied-ai-course-online/lessons/confusion-matrix-tpr-fpr-fnr-tnr-1/'>confusion matrix</a> with predicted and original labels of test data points. Please visualize your confusion matrices using <a href='https://seaborn.pydata.org/generated/seaborn.heatmap.html'>seaborn heatmaps.\n",
    "    <img src='confusion_matrix.png' width=300px></li>\n",
    "        </ul>\n",
    "    </li>\n",
    "    <br>\n",
    "    <li><strong>Conclusion</strong>\n",
    "        <ul>\n",
    "    <li>You need to summarize the results at the end of the notebook, summarize it in the table format. To print out a table please refer to this prettytable library<a href='http://zetcode.com/python/prettytable/'>  link</a> \n",
    "        <img src='summary.JPG' width=400px>\n",
    "    </li>\n",
    "        </ul>\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4><font color='red'>Note: Data Leakage</font></h4>\n",
    "\n",
    "1. There will be an issue of data-leakage if you vectorize the entire data and then split it into train/cv/test.\n",
    "2. To avoid the issue of data-leakag, make sure to split your data first and then vectorize it. \n",
    "3. While vectorizing your data, apply the method fit_transform() on you train data, and apply the method transform() on cv/test data.\n",
    "4. For more details please go through this <a href='https://soundcloud.com/applied-ai-course/leakage-bow-and-tfidf'>link.</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Applying SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [5.1] Linear SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [5.1.1] Applying Linear SVM on BOW,<font color='red'> SET 1</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Please write all the code with proper documentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [5.1.2] Applying Linear SVM on TFIDF,<font color='red'> SET 2</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Please write all the code with proper documentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [5.1.3]  Applying Linear SVM on AVG W2V,<font color='red'> SET 3</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Please write all the code with proper documentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [5.1.4]  Applying Linear SVM on TFIDF W2V,<font color='red'> SET 4</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Please write all the code with proper documentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [5.2] RBF SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [5.2.1] Applying RBF SVM on BOW,<font color='red'> SET 1</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Please write all the code with proper documentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [5.2.2] Applying RBF SVM on TFIDF,<font color='red'> SET 2</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Please write all the code with proper documentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [5.2.3]  Applying RBF SVM on AVG W2V,<font color='red'> SET 3</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Please write all the code with proper documentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [5.2.4]  Applying RBF SVM on TFIDF W2V,<font color='red'> SET 4</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Please write all the code with proper documentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [6] Conclusions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Please compare all your models using Prettytable library"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
